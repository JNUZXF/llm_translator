# BGE-M3 æ‰¹å¤„ç†åµŒå…¥å™¨ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

BGE-M3 æ‰¹å¤„ç†åµŒå…¥å™¨æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„æ–‡æœ¬å‘é‡åŒ–å·¥å…·ï¼Œä¸“ä¸ºå¤„ç†å¤§é‡æ–‡æœ¬è€Œè®¾è®¡ã€‚å®ƒæ”¯æŒå¤šçº¿ç¨‹å¤„ç†ã€æ™ºèƒ½ç¼“å­˜ã€è¿›åº¦æ˜¾ç¤ºå’Œç»“æœä¿å­˜ç­‰åŠŸèƒ½ã€‚

## ä¸»è¦ç‰¹æ€§

### ğŸš€ æ€§èƒ½ä¼˜åŒ–
- **å¤šçº¿ç¨‹å¤„ç†**: ä½¿ç”¨ThreadPoolExecutorå®ç°å¹¶å‘å¤„ç†
- **æ™ºèƒ½æ‰¹å¤„ç†**: è‡ªåŠ¨å°†æ–‡æœ¬åˆ†æ‰¹å¤„ç†ï¼Œæé«˜æ•ˆç‡
- **æœ¬åœ°æ¨¡å‹ä¼˜å…ˆ**: ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œé¿å…ç½‘ç»œä¾èµ–
- **GPUåŠ é€Ÿ**: è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨CUDAè®¾å¤‡

### ğŸ’¾ æ™ºèƒ½ç¼“å­˜
- **æ–‡æœ¬å“ˆå¸Œç¼“å­˜**: ç›¸åŒæ–‡æœ¬ä¸ä¼šé‡å¤è®¡ç®—
- **çº¿ç¨‹å®‰å…¨**: ä½¿ç”¨é”æœºåˆ¶ä¿è¯ç¼“å­˜ä¸€è‡´æ€§
- **ç¼“å­˜ç»Ÿè®¡**: æä¾›ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡

### ğŸ“Š è¿›åº¦ç›‘æ§
- **å®æ—¶è¿›åº¦æ¡**: ä½¿ç”¨tqdmæ˜¾ç¤ºå¤„ç†è¿›åº¦
- **è¯¦ç»†ç»Ÿè®¡**: æä¾›å¤„ç†æ—¶é—´ã€é€Ÿåº¦ç­‰ç»Ÿè®¡ä¿¡æ¯
- **é”™è¯¯å¤„ç†**: ä¼˜é›…å¤„ç†æ‰¹æ¬¡å¤±è´¥ï¼Œä¸å½±å“æ•´ä½“è¿›åº¦

## å¿«é€Ÿå¼€å§‹

### 1. åŸºæœ¬ä½¿ç”¨

```python
from agent.utils.agent_tool_bge_embedder import batch_encode_texts

# å‡†å¤‡æ–‡æœ¬æ•°æ®
texts = [
    "è¿™æ˜¯ç¬¬ä¸€ä¸ªæ–‡æœ¬",
    "è¿™æ˜¯ç¬¬äºŒä¸ªæ–‡æœ¬",
    "è¿™æ˜¯ç¬¬ä¸‰ä¸ªæ–‡æœ¬",
    # ... æ›´å¤šæ–‡æœ¬
]

# æ‰¹é‡ç¼–ç 
results = batch_encode_texts(
    texts=texts,
    batch_size=32,        # æ¯æ‰¹å¤„ç†32ä¸ªæ–‡æœ¬
    max_workers=4,        # ä½¿ç”¨4ä¸ªçº¿ç¨‹
    cache_results=True,   # å¯ç”¨ç¼“å­˜
    show_progress=True    # æ˜¾ç¤ºè¿›åº¦æ¡
)

# è·å–ç»“æœ
embeddings = results['embeddings']  # numpyæ•°ç»„
processed_texts = results['texts']  # æˆåŠŸå¤„ç†çš„æ–‡æœ¬
stats = results['stats']           # ç»Ÿè®¡ä¿¡æ¯
```

### 2. ä½¿ç”¨ç±»æ¥å£

```python
from agent.utils.agent_tool_bge_embedder import BGEBatchEmbedder

# åˆ›å»ºåµŒå…¥å™¨å®ä¾‹
embedder = BGEBatchEmbedder(
    batch_size=64,
    max_workers=8,
    cache_results=True,
    show_progress=True
)

# æ‰¹é‡å¤„ç†
results = embedder.batch_encode(texts)

# ä¿å­˜ç»“æœ
embedder.save_results(results, "my_embeddings.pkl")

# åŠ è½½ç»“æœ
loaded_results = embedder.load_results("my_embeddings.pkl")
```

## é«˜çº§ç”¨æ³•

### 1. å¤§è§„æ¨¡æ–‡æœ¬å¤„ç†

```python
# å¤„ç†10ä¸‡ä¸ªæ–‡æœ¬çš„æ¨èé…ç½®
large_texts = [f"æ–‡æœ¬å†…å®¹ {i}" for i in range(100000)]

results = batch_encode_texts(
    texts=large_texts,
    batch_size=128,       # è¾ƒå¤§çš„æ‰¹æ¬¡å¤§å°
    max_workers=8,        # æ›´å¤šçº¿ç¨‹
    cache_results=True,   # å¯ç”¨ç¼“å­˜ä»¥å¤„ç†é‡å¤æ–‡æœ¬
    show_progress=True
)

print(f"å¤„ç†äº† {len(results['texts'])} ä¸ªæ–‡æœ¬")
print(f"å¤„ç†é€Ÿåº¦: {results['stats']['embeddings_per_second']:.2f} æ–‡æœ¬/ç§’")
```

### 2. å†…å­˜ä¼˜åŒ–å¤„ç†

```python
# å¯¹äºè¶…å¤§è§„æ¨¡æ–‡æœ¬ï¼Œåˆ†å—å¤„ç†
def process_large_texts_in_chunks(texts, chunk_size=10000):
    all_embeddings = []
    all_texts = []
    
    for i in range(0, len(texts), chunk_size):
        chunk = texts[i:i + chunk_size]
        print(f"å¤„ç†ç¬¬ {i//chunk_size + 1} å—ï¼Œå…± {len(chunk)} ä¸ªæ–‡æœ¬")
        
        results = batch_encode_texts(
            texts=chunk,
            batch_size=64,
            max_workers=6,
            cache_results=True
        )
        
        all_embeddings.append(results['embeddings'])
        all_texts.extend(results['texts'])
    
    # åˆå¹¶æ‰€æœ‰ç»“æœ
    import numpy as np
    final_embeddings = np.vstack(all_embeddings)
    
    return {
        'texts': all_texts,
        'embeddings': final_embeddings
    }

# ä½¿ç”¨ç¤ºä¾‹
large_results = process_large_texts_in_chunks(very_large_texts)
```

### 3. ç›¸ä¼¼æ€§æœç´¢

```python
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# è·å–åµŒå…¥å‘é‡
results = batch_encode_texts(texts)
embeddings = results['embeddings']

# æŸ¥è¯¢æ–‡æœ¬
query_text = "æŸ¥è¯¢å†…å®¹"
query_result = batch_encode_texts([query_text])
query_embedding = query_result['embeddings'][0]

# è®¡ç®—ç›¸ä¼¼æ€§
similarities = cosine_similarity([query_embedding], embeddings)[0]

# è·å–æœ€ç›¸ä¼¼çš„å‰5ä¸ªæ–‡æœ¬
top_indices = np.argsort(similarities)[::-1][:5]
for i, idx in enumerate(top_indices):
    print(f"ç¬¬{i+1}ç›¸ä¼¼: {texts[idx]} (ç›¸ä¼¼åº¦: {similarities[idx]:.4f})")
```

## é…ç½®å‚æ•°è¯¦è§£

### BGEBatchEmbedder å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `model_path` | str | None | æ¨¡å‹è·¯å¾„ï¼ŒNoneæ—¶è‡ªåŠ¨å¯»æ‰¾æœ¬åœ°æ¨¡å‹ |
| `batch_size` | int | 32 | æ¯æ‰¹å¤„ç†çš„æ–‡æœ¬æ•°é‡ |
| `max_workers` | int | 4 | æœ€å¤§çº¿ç¨‹æ•° |
| `cache_results` | bool | True | æ˜¯å¦å¯ç”¨ç¼“å­˜ |
| `show_progress` | bool | True | æ˜¯å¦æ˜¾ç¤ºè¿›åº¦æ¡ |

### æ€§èƒ½è°ƒä¼˜å»ºè®®

#### æ‰¹æ¬¡å¤§å° (batch_size)
- **å°æ–‡æœ¬ (<100å­—ç¬¦)**: 64-128
- **ä¸­ç­‰æ–‡æœ¬ (100-500å­—ç¬¦)**: 32-64
- **é•¿æ–‡æœ¬ (>500å­—ç¬¦)**: 16-32
- **GPUå†…å­˜é™åˆ¶**: æ ¹æ®æ˜¾å­˜å¤§å°è°ƒæ•´

#### çº¿ç¨‹æ•° (max_workers)
- **CPUå¯†é›†å‹**: CPUæ ¸å¿ƒæ•°
- **I/Oå¯†é›†å‹**: CPUæ ¸å¿ƒæ•° Ã— 2
- **GPUå¤„ç†**: 2-4ä¸ªçº¿ç¨‹å³å¯
- **å†…å­˜é™åˆ¶**: é¿å…è¿‡å¤šçº¿ç¨‹å¯¼è‡´å†…å­˜æº¢å‡º

## é”™è¯¯å¤„ç†

### å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ¡ˆ

#### 1. æ¨¡å‹åŠ è½½å¤±è´¥
```
é”™è¯¯: æ¨¡å‹åŠ è½½å¤±è´¥
è§£å†³: æ£€æŸ¥æœ¬åœ°æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´ï¼Œæˆ–ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸
```

#### 2. å†…å­˜ä¸è¶³
```
é”™è¯¯: CUDA out of memory
è§£å†³: å‡å°‘batch_sizeæˆ–max_workers
```

#### 3. æ‰¹æ¬¡å¤„ç†å¤±è´¥
```
é”™è¯¯: æ‰¹æ¬¡å¤„ç†å¤±è´¥
è§£å†³: æ£€æŸ¥æ–‡æœ¬å†…å®¹æ˜¯å¦æœ‰ç‰¹æ®Šå­—ç¬¦ï¼Œè€ƒè™‘æ–‡æœ¬é¢„å¤„ç†
```

## æ€§èƒ½åŸºå‡†

### æµ‹è¯•ç¯å¢ƒ
- **CPU**: Intel i7-10700K
- **GPU**: NVIDIA RTX 3080
- **å†…å­˜**: 32GB DDR4
- **æ–‡æœ¬**: å¹³å‡200å­—ç¬¦

### æ€§èƒ½æ•°æ®

| é…ç½® | æ–‡æœ¬æ•°é‡ | å¤„ç†æ—¶é—´ | é€Ÿåº¦ (æ–‡æœ¬/ç§’) |
|------|----------|----------|----------------|
| å•çº¿ç¨‹ | 1,000 | 45.2s | 22.1 |
| 4çº¿ç¨‹ | 1,000 | 12.8s | 78.1 |
| 8çº¿ç¨‹ | 1,000 | 8.9s | 112.4 |
| 8çº¿ç¨‹+ç¼“å­˜ | 1,000 | 6.2s | 161.3 |

## æœ€ä½³å®è·µ

### 1. æ–‡æœ¬é¢„å¤„ç†
```python
def preprocess_texts(texts):
    """æ–‡æœ¬é¢„å¤„ç†"""
    processed = []
    for text in texts:
        # å»é™¤å¤šä½™ç©ºç™½
        text = ' '.join(text.split())
        # é™åˆ¶é•¿åº¦
        if len(text) > 512:
            text = text[:512]
        processed.append(text)
    return processed

# ä½¿ç”¨é¢„å¤„ç†
clean_texts = preprocess_texts(raw_texts)
results = batch_encode_texts(clean_texts)
```

### 2. ç»“æœç®¡ç†
```python
# ä¿å­˜å¸¦æ—¶é—´æˆ³çš„ç»“æœ
import datetime

timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
save_path = f"embeddings_{timestamp}.pkl"

embedder.save_results(results, save_path)
```

### 3. ç›‘æ§èµ„æºä½¿ç”¨
```python
import psutil
import time

def monitor_resources():
    """ç›‘æ§èµ„æºä½¿ç”¨"""
    while True:
        cpu_percent = psutil.cpu_percent()
        memory_percent = psutil.virtual_memory().percent
        print(f"CPU: {cpu_percent}%, å†…å­˜: {memory_percent}%")
        time.sleep(1)

# åœ¨å¤„ç†è¿‡ç¨‹ä¸­ç›‘æ§
import threading
monitor_thread = threading.Thread(target=monitor_resources)
monitor_thread.daemon = True
monitor_thread.start()

# å¼€å§‹å¤„ç†
results = batch_encode_texts(texts)
```

## æ•…éšœæ’é™¤

### 1. æ£€æŸ¥æ¨¡å‹çŠ¶æ€
```python
from agent.utils.agent_tool_bge_embedder import check_local_model_status

# æ£€æŸ¥æœ¬åœ°æ¨¡å‹çŠ¶æ€
check_local_model_status()
```

### 2. æ¸…ç†ç¼“å­˜
```python
# æ¸…ç†ç¼“å­˜ä»¥é‡Šæ”¾å†…å­˜
embedder.clear_cache()
```

### 3. è°ƒè¯•æ¨¡å¼
```python
import logging

# å¯ç”¨è¯¦ç»†æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)

# è¿è¡Œå¤„ç†
results = batch_encode_texts(texts)
```

## æ€»ç»“

BGE-M3 æ‰¹å¤„ç†åµŒå…¥å™¨ä¸ºå¤§è§„æ¨¡æ–‡æœ¬å¤„ç†æä¾›äº†é«˜æ•ˆã€å¯é çš„è§£å†³æ–¹æ¡ˆã€‚é€šè¿‡åˆç†é…ç½®å‚æ•°å’Œéµå¾ªæœ€ä½³å®è·µï¼Œå¯ä»¥æ˜¾è‘—æå‡æ–‡æœ¬å‘é‡åŒ–çš„æ•ˆç‡ã€‚

ä¸»è¦ä¼˜åŠ¿ï¼š
- âœ… å¤šçº¿ç¨‹å¹¶å‘å¤„ç†
- âœ… æ™ºèƒ½ç¼“å­˜æœºåˆ¶
- âœ… æœ¬åœ°æ¨¡å‹ä¼˜å…ˆ
- âœ… è¯¦ç»†è¿›åº¦ç›‘æ§
- âœ… çµæ´»çš„é…ç½®é€‰é¡¹
- âœ… å®Œå–„çš„é”™è¯¯å¤„ç†

é€‚ç”¨åœºæ™¯ï¼š
- ğŸ“š å¤§è§„æ¨¡æ–‡æ¡£å‘é‡åŒ–
- ğŸ” ç›¸ä¼¼æ€§æœç´¢ç³»ç»Ÿ
- ğŸ“Š æ–‡æœ¬åˆ†æå’ŒæŒ–æ˜
- ğŸ¤– RAGç³»ç»Ÿæ„å»º
- ğŸ’¾ å‘é‡æ•°æ®åº“æ„å»º 